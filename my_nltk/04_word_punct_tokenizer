from nltk.tokenize import WordPunctTokenizer

# Initialize the tokenizer
tokenizer = WordPunctTokenizer()

example_string = "Hello, world! It's a beautiful day."

# Tokenize the string
tokens = tokenizer.tokenize(example_string)

print("Tokens:", tokens)
